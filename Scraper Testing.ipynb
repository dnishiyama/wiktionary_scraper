{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T05:11:36.761457Z",
     "start_time": "2018-07-02T05:11:36.535584Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mysql.connector, json, os, requests, re\n",
    "from bs4 import BeautifulSoup\n",
    "conn = mysql.connector.connect(\n",
    "    user=os.environ['MYSQL_DB_USER'], \n",
    "    password=os.environ['MYSQL_DB_PASSWORD'], \n",
    "    host='127.0.0.1', \n",
    "    database='etymology_explorer_staging')\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T05:11:36.844015Z",
     "start_time": "2018-07-02T05:11:36.833784Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_pos = ['adfix', 'adjective', 'adnoun', 'adverb', 'article', 'auxiliary verb', 'cardinal number', 'collective numeral',\n",
    "           'conjunction', 'coverb', 'demonstrative determiner', 'demonstrative pronoun', 'determinative', 'determiner',\n",
    "           'gerund', 'indefinite pronoun', 'infinitive', 'interjection', 'interrogative pronoun', 'intransitive verb',\n",
    "           'noun', 'number', 'numeral', 'ordinal', 'ordinal number', 'part of speech', 'participle', 'particle',\n",
    "           'personal pronoun', 'phrasal preposition', 'possessive adjective', 'possessive determiner', 'possessive pronoun',\n",
    "           'postposition', 'preposition', 'preverb', 'pronoun', 'quasi-adjective', 'reciprocal pronoun', 'reflexive pronoun',\n",
    "           'relative pronoun', 'speech disfluency', 'substantive', 'transitive', 'transitive verb', 'verb', 'verbal noun']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T05:11:36.932373Z",
     "start_time": "2018-07-02T05:11:36.929965Z"
    }
   },
   "outputs": [],
   "source": [
    "all_pos += ['suffix', 'prefix', 'infix', 'root']; all_pos; # Needed for Reconstructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Get urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Ok so I want to have the data staged somewhere so that I can check it before I update everything else. I could move it into a dataframe. I already have one that stores a ton of information. The definitions could be one big array, or it could be it's own csv with definitions as a separate list. I think I'm going to do that first. It is more flexible. And I can do that for the pronunciations. It will be the same as the other DF. I think I could also just have it append all the results to a file\n",
    "- word, language, etymology\n",
    "- word, language, pronunciation\n",
    "- word, language, pos, definition\n",
    "\n",
    "Cat is a good test for multiple etymologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T02:52:17.069423Z",
     "start_time": "2018-06-23T02:52:14.348667Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Get the list of word-language pairs\n",
    "df = pd.read_csv('~/etymology_files/ety_master.csv', \n",
    "                 usecols = ['word', 'language'], \n",
    "                 converters={'word' : str, 'language': str}\n",
    "                )\n",
    "\n",
    "# Set all non-reconstructions to be 'None'\n",
    "normal_language_rows = [not language.startswith('Proto') for language in df['language'].tolist()] #bools\n",
    "df.loc[normal_language_rows, 'language'] = None\n",
    "df = df.drop_duplicates()\n",
    "url_terms = [row[0] if row[1] is None else 'Reconstruction:'+row[1]+'/'+row[0] for row in df.values]\n",
    "urls = ['https://en.wiktionary.org/api/rest_v1/page/html/' + term for term in url_terms]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now try from MYSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "self.user = os.environ['MYSQL_DB_USER']\n",
    "self.password = os.environ['MYSQL_DB_PASSWORD']\n",
    "self.host = '127.0.0.1'\n",
    "self.database = 'etymology_explorer_staging'\n",
    "self.conn = mysql.connector.connect(user=self.user, password=self.password, host=self.host, database=self.database)\n",
    "self.cursor = self.conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T05:52:27.781044Z",
     "start_time": "2018-06-27T05:51:58.973872Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cursor.execute('SELECT word, language_name \\\n",
    "                    FROM etymologies e, languages l\\\n",
    "                    WHERE e.language_code = l.language_code AND _id NOT IN (SELECT etymology_id FROM entry_connections) \\\n",
    "                    limit 10')\n",
    "wls = [[w.decode('utf-8','replace').strip(), l.decode()] for w, l in cursor.fetchall()]; wls\n",
    "url_terms = [row[0] if not row[1].startswith('Proto') else 'Reconstruction:'+row[1]+'/'+row[0] for row in wls]; url_terms\n",
    "# for url in set(url_terms):\n",
    "#     print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('~/etymology_files/ety_master.csv',\n",
    "                 usecols = ['word', 'language'],\n",
    "                 converters={'word' : str, 'language': str})\n",
    "\n",
    "        # Set all non-reconstructions to be 'None'\n",
    "        normal_language_rows = [not language.startswith('Proto') for language in df['language'].tolist()] #bools\n",
    "        df.loc[normal_language_rows, 'language'] = None\n",
    "        df = df.drop_duplicates()\n",
    "        url_terms = [row[0] if row[1] is None else 'Reconstruction:'+row[1]+'/'+row[0] for row in df.values]\n",
    "        urls = ['https://en.wiktionary.org/api/rest_v1/page/html/' + term for term in url_terms[:5] + ['cat']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape Wiktionary Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T05:19:23.457452Z",
     "start_time": "2018-07-02T05:19:23.427030Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDefsFromPOS(ety_pronunc_pos_node):\n",
    "    keep_def_tags = ('i', 'b', 'a', 'span', None)\n",
    "    node_data = []\n",
    "    for li in list(ety_pronunc_pos_node.parent.find('ol').children): # get defs from ordered list\n",
    "        if li.name != 'li': continue # This is a newline tag\n",
    "\n",
    "        if li.find('ol'): #Ordered list means the sub items are the definition\n",
    "            for sub_li in list(li.find('ol').children):\n",
    "                if sub_li.name != 'li': continue # Skip newline tags\n",
    "\n",
    "                for child in sub_li.children:\n",
    "                    if child.name not in keep_def_tags: child.clear() #Get rid of quotes and subitems\n",
    "\n",
    "                node_data.append(sub_li.text.strip())\n",
    "\n",
    "        else: # otherwise grab the text\n",
    "\n",
    "            for child in li.children:\n",
    "                if child.name not in keep_def_tags: child.clear() #Get rid of quotes and subitems\n",
    "            node_data.append(li.text.strip())\n",
    "    return node_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T05:25:08.075141Z",
     "start_time": "2018-07-02T05:25:07.821824Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h2 id=\"English\">English</h2>\n",
      "<h3 id=\"Etymology\">Etymology</h3>\n",
      "<h3 id=\"Pronunciation\">Pronunciation</h3>\n",
      "<h3 id=\"Adjective\">Adjective</h3>\n",
      "{\n",
      "    \"term\": \"self-referential\",\n",
      "    \"English\": [\n",
      "        {\n",
      "            \"etymology\": \"self- + referential.\",\n",
      "            \"pronunciation\": \"/\\u02c8s\\u025blf \\u0279\\u025bf\\u0259\\u02c8\\u0279\\u025bn\\u0283l/\",\n",
      "            \"adjective\": [\n",
      "                \"That or who refers to itself or oneself.\",\n",
      "                \"(specifically) In a literary work: referring to the author or the author's other works.\"\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "word='self-referential'#'Reconstruction:Proto-Indo-European%2Fkerp-'; #word='犬' #ǵerh₂-\n",
    "response = requests.get(f'https://en.wiktionary.org/api/rest_v1/page/html/{word}'); response\n",
    "page = response.url.replace('https://en.wiktionary.org/api/rest_v1/page/html/', '')\n",
    "page = re.sub('Reconstruction:[^\\/]+?\\/(.*)', r'\\1', page) #Remove reconstruction text if necessary\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "page_data = {'term': page} # Variable to store the data\n",
    "\n",
    "for lang_node in soup.find_all('h2'): # Go through each Language\n",
    "    print(lang_node)\n",
    "    language = lang_node.text.strip()\n",
    "    language_entries = [{}]\n",
    "\n",
    "    for ety_pronunc_pos_node in lang_node.parent.find_all('h3'): # Go through each ety,pronu, or pos\n",
    "        print(ety_pronunc_pos_node)\n",
    "        node_data = []\n",
    "        node_class = re.sub('_\\d+| \\d+', '', ety_pronunc_pos_node.text).lower() #removed '_x' info\n",
    "#         node_text = ety_pronunc_pos_node.text.lower()\n",
    "\n",
    "        if node_class == 'etymology':\n",
    "            #Only looking at the first <p> element for etymology text\n",
    "            etymology_text = ety_pronunc_pos_node.parent.find('p').text.replace('\\u200e', '')\n",
    "            entry_data = {'etymology': etymology_text}\n",
    "            \n",
    "            for sub_ety_pos in ety_pronunc_pos_node.parent.find_all('h4'):\n",
    "                if sub_ety_pos.text.lower() in all_pos:\n",
    "                    entry_data[sub_ety_pos.text.lower()] = getDefsFromPOS(sub_ety_pos)\n",
    "\n",
    "            if any(['etymology' in entry for entry in language_entries]): #If an etymology already exists add to new entry\n",
    "                language_entries.append(entry_data)\n",
    "            else:\n",
    "                language_entries[0].update(entry_data)\n",
    "                \n",
    "        # Need to see if there are sub items of this etymology\n",
    "        elif node_class == 'pronunciation':\n",
    "            ipa_nodes = ety_pronunc_pos_node.parent.select('span.IPA') #dataquest.io/blog/web-scraping-tutorial-python/\n",
    "            if ipa_nodes: #Only add pronunciation if there are ipa_nodes\n",
    "                node_data = ipa_nodes[0].text\n",
    "                language_entries[0]['pronunciation'] = node_data\n",
    "\n",
    "        elif node_class in all_pos: # Here are the definitions\n",
    "            language_entries[0][node_class] = getDefsFromPOS(ety_pronunc_pos_node)\n",
    "\n",
    "        else: # Skip all other node_classes\n",
    "            continue\n",
    "\n",
    "        page_data[language] = language_entries #Add all the language entries to the language \n",
    "print (json.dumps(page_data, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Parsed response into SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T18:05:48.560781Z",
     "start_time": "2018-06-22T18:05:48.556838Z"
    },
    "hidden": true
   },
   "source": [
    "- Languages (1,2,3,4)\n",
    "    - Etymology (1,2,3,4)\n",
    "    - Pronunciation (1,2,3,4)\n",
    "    - POS (1,2,3,4)\n",
    "        - Definitions (1,2,3,4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Need the scraper to determine the number of entries:\n",
    "- Hand (English) has one entry with multiple POS and one etymology\n",
    "- Cat (English) has 9 entries each with one etymology and multiple POS\n",
    "- Are there any entries with multiple etymologies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T04:28:28.746580Z",
     "start_time": "2018-06-27T04:28:28.742839Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getNewKey(column, table):\n",
    "    cursor.execute(f'SELECT max({column}) FROM {table}')\n",
    "    max_entry_id = cursor.fetchone()[0]; \n",
    "    new_entry_id = max_entry_id + 1 if max_entry_id is not None else 0\n",
    "    return new_entry_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T04:41:13.589086Z",
     "start_time": "2018-06-27T04:41:13.579952Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def insert(table, **kwargs):\n",
    "    columns = [str(k) for k,v in kwargs.items()]; columns\n",
    "    values = [str(v) if type(v) != str else repr(v)  for k,v in kwargs.items()]; values\n",
    "    col_text = '('+', '.join(columns)+')'\n",
    "    val_text = '('+', '.join(values)+')'\n",
    "    sql_statement = f'INSERT INTO {table}{col_text} VALUES {val_text}'\n",
    "    print(sql_statement)\n",
    "    cursor.execute(sql_statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T06:42:59.870633Z",
     "start_time": "2018-06-27T06:42:59.868294Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T06:43:55.409629Z",
     "start_time": "2018-06-27T06:43:55.404255Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T06:43:40.375630Z",
     "start_time": "2018-06-27T06:43:40.362204Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "text = \"\"\"{'English': [{'etymology': 'From Middle English apprile, Aprill, re-Latinised from Middle English aueril, from Old French avrill, from Latin Aprīlis (“of the month of the goddess Venus”), perhaps based on Etruscan 𐌖𐌓𐌐𐌀 (Apru), from Ancient Greek Αφροδίτη (Aphrodítē, “Venus”).', 'pronunciation': '/ˈeɪ.pɹɪl/'}], 'Afrikaans': [{'noun': ['April']}], 'Cebuano': [{'etymology': 'From English April, from Middle English apprile, re-Latinized from aueril, from Old French avrill, from Latin Aprīlis (“of the month of the goddess Venus”), perhaps based on Etruscan 𐌖𐌓𐌐𐌀 (Apru), from Ancient Greek Αφροδίτη (Aphrodítē, “Venus”).'}], 'German': [{'pronunciation': '/aˈpʁɪl/', 'noun': ['April']}], 'Malay': [{'etymology': 'From English April, from Middle English apprile, from aueril, from Old French avrill, from Latin Aprīlis.', 'pronunciation': '[aprel]'}]}\"\"\"\n",
    "table = 'entry_etymologies'\n",
    "kwargs = {'etymology': text}\n",
    "columns = [str(k) for k,v in kwargs.items()]; columns\n",
    "values = [str(v) if type(v) != str else repr(v)  for k,v in kwargs.items()]; values\n",
    "col_text = '('+', '.join(columns)+')'\n",
    "val_text = '('+', '.join(values)+')'\n",
    "\n",
    "\n",
    "cursor.execute('SET NAMES utf8mb4;')\n",
    "# cursor.execute('SET CHARACTER SET utf8mb4;')\n",
    "# cursor.execute('SET character_set_connection=utf8mb4;')\n",
    "\n",
    "cursor.execute(\"INSERT INTO entry_etymologies(etymology) VALUES (%s)\", [text.encode()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T06:48:17.401694Z",
     "start_time": "2018-06-28T06:48:17.313588Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Clear out the databases\n",
    "cursor.execute('DELETE FROM entry_connections')\n",
    "cursor.execute('DELETE FROM entry_pronunciations')\n",
    "cursor.execute('DELETE FROM entry_etymologies')\n",
    "cursor.execute('DELETE FROM entry_pos')\n",
    "cursor.execute('DELETE FROM entry_definitions')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T05:15:33.684758Z",
     "start_time": "2018-06-27T05:15:33.581663Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('/home/ubuntu/scrapy/wiktionary_scraper/output/test3.json', 'r') as results:\n",
    "    for line in results:\n",
    "        this_data = json.loads(line)\n",
    "        if this_data['term'] == 'cat': break\n",
    "        \n",
    "# print('SCRAPED DATA')\n",
    "# print(json.dumps(this_data, indent=4))\n",
    "        \n",
    "word = this_data['term']\n",
    "del this_data['term']\n",
    "\n",
    "for lang, entries in this_data.items():\n",
    "#     print()\n",
    "#     print('STORED DATA')\n",
    "    language = lang\n",
    "#     print(language)\n",
    "#     word='asdfasdf'\n",
    "    cursor.execute(f'SELECT _id FROM etymologies e, languages l WHERE word = \"{word}\" and language_name = \"{language}\" and e.language_code = l.language_code')\n",
    "    ety_id_result = cursor.fetchone(); etymology\n",
    "    if ety_id_result is not None: \n",
    "        ety_id = ety_id_result[0]\n",
    "    else:\n",
    "        ety_id = getNewKey('_id', 'etymologies') + 1\n",
    "        cursor.execute(\n",
    "                    f'INSERT INTO etymologies(_id, word, language_code) \\\n",
    "                        SELECT {ety_id}, \"{word}\", language_code FROM languages WHERE language_name = \"{language}\"')\n",
    "    \n",
    "    for entry in entries:\n",
    "        # Get a new entry key, make the entry connection\n",
    "        new_entry_id = getNewKey('entry_id', 'entry_connections'); print(\"new_entry_id:\", new_entry_id)\n",
    "        insert('entry_connections', etymology_id=ety_id, entry_id=new_entry_id)\n",
    "        \n",
    "        for node_key, node_value in entry.items():\n",
    "            if node_key == 'pronunciation':\n",
    "#                 print('node k,v:', node_key, node_value)\n",
    "                insert('entry_pronunciations', pronunciation=node_value, entry_id=new_entry_id)\n",
    "    \n",
    "            elif node_key == 'etymology':\n",
    "                insert('entry_etymologies', etymology=node_value, entry_id=new_entry_id)\n",
    "                \n",
    "            elif node_key in all_pos:\n",
    "                new_pos_key = getNewKey('pos_id', 'entry_pos'); print(\"new_pos_key:\", new_pos_key)\n",
    "                insert('entry_pos', pos=node_key, pos_id=new_pos_key, entry_id=new_entry_id)\n",
    "                \n",
    "                for definition in node_value:\n",
    "#                     print('definition:', definition, new_pos_key)\n",
    "                    insert('entry_definitions', definition=definition, pos_id=new_pos_key)\n",
    "                \n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T04:45:54.858275Z",
     "start_time": "2018-06-27T04:45:54.852448Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "These commands are mainly selecting to see if data already exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-26T21:16:54.994647Z",
     "start_time": "2018-06-26T21:16:54.946095Z"
    },
    "code_folding": [],
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('/home/ubuntu/scrapy/wiktionary_scraper/output/test3.json', 'r') as results:\n",
    "    for line in results:\n",
    "        this_data = json.loads(line)\n",
    "        if this_data['term'] == 'cat': break\n",
    "        \n",
    "print('SCRAPED DATA')\n",
    "print(json.dumps(this_data, indent=4))\n",
    "        \n",
    "word = this_data['term']\n",
    "del this_data['term']\n",
    "\n",
    "for lang, values in this_data.items():\n",
    "    print()\n",
    "    print('STORED DATA')\n",
    "    language = lang\n",
    "    \n",
    "    cursor.execute(f'SELECT _id FROM etymologies e, languages l WHERE word = \"{word}\" and language_name = \"{language}\" and e.language_code = l.language_code')\n",
    "    ety_id = cursor.fetchone()[0]; print('etymology:', ety_id)\n",
    "    \n",
    "    # Check for matching to existing entries here\n",
    "    cursor.execute(f'SELECT entry_id FROM entry_connections WHERE etymology_id = {ety_id}')\n",
    "    entry_ids = [item[0] for item in cursor.fetchall()]; print('entry_ids:', entry_ids)\n",
    "    \n",
    "    # Insert new entry ID\n",
    "#     new_entry_ids\n",
    "    # Add each element to SQL with that entry ID\n",
    "    \n",
    "    \n",
    "    #What if multiple entries\n",
    "\n",
    "    cursor.execute(f'SELECT definition FROM entry_definitions WHERE entry_id = {entry_ids[0]}')\n",
    "    definitions = cursor.fetchall(); print('definitions:', definitions)\n",
    "\n",
    "    cursor.execute(f'SELECT etymology FROM entry_etymologies WHERE entry_id= {entry_ids[0]}')\n",
    "    etymologies = cursor.fetchall(); print('etymologies:', etymologies)\n",
    "\n",
    "    cursor.execute(f'SELECT part_of_speech FROM entry_pos WHERE entry_id = {entry_ids[0]}')\n",
    "    pos = cursor.fetchall(); print('pos:', pos)\n",
    "\n",
    "    cursor.execute(f'SELECT pronunciations FROM entry_pronunciations WHERE entry_id = {entry_ids[0]}')\n",
    "    pronunciations = cursor.fetchall(); print('pronunciations:', pronunciations)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Spider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T05:11:41.596888Z",
     "start_time": "2018-07-02T05:11:40.214075Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import wiktionary_scraper.spiders.wiktionary_spider as ws\n",
    "import wiktionary_scraper.pipelines as pipelines\n",
    "import scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T04:52:57.868789Z",
     "start_time": "2018-07-02T04:52:57.866284Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ??scrapy.http.response\n",
    "# ??ws.WiktionarySpider\n",
    "# ??scrapy.Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T05:17:36.320790Z",
     "start_time": "2018-07-02T05:17:36.226273Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<200 https://en.wiktionary.org/api/rest_v1/page/html/self-referential>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term='self-referential'#'Reconstruction:Proto-Indo-European%2Fkerp-'#'犬'\n",
    "url = f'https://en.wiktionary.org/api/rest_v1/page/html/{term}'; url\n",
    "temp_request = requests.get(url)\n",
    "body = temp_request.content; body\n",
    "status = temp_request.status_code; status\n",
    "spider = ws.WiktionarySpider()\n",
    "pipe = pipelines.WiktionaryScraperPipeline()\n",
    "pipe.open_spider(spider)\n",
    "request = scrapy.Request(url, meta = {'term': term})\n",
    "response = scrapy.http.response.Response(url=url, body=body, request=request, status=status); response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T05:17:38.628196Z",
     "start_time": "2018-07-02T05:17:38.594405Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'term': 'self-referential', 'status': 200, 'English': [{'etymology': 'self- +\\u200e referential.', 'pronunciation': '/ˈsɛlf ɹɛfəˈɹɛnʃl/', 'adjective': ['That or who refers to itself or oneself.', \"(specifically) In a literary work: referring to the author or the author's other works.\"]}]}\n"
     ]
    }
   ],
   "source": [
    "for resp in spider.parse(response):\n",
    "    print(resp)\n",
    "#     print(pipe.process_item(resp, spider))\n",
    "# pipe.close_spider(spider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T05:32:34.453212Z",
     "start_time": "2018-06-28T05:32:34.322262Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cursor.execute('SELECT * FROM languages')\n",
    "lc2ln = {row[1].decode(): row[0].decode() for row in cursor.fetchall()}; lc2ln['alu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T05:37:34.419802Z",
     "start_time": "2018-06-28T05:37:24.940179Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cursor.execute('SELECT word, language_code FROM etymologies WHERE _id NOT IN (SELECT DISTINCT etymology_id FROM entry_connections)')\n",
    "new_terms = [[row[0].decode().strip(), row[1].decode()] for row in cursor.fetchall()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T05:43:32.166005Z",
     "start_time": "2018-06-28T05:43:32.161987Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url_terms = [row[0] if not row[1].endswith('-pro') else 'Reconstruction:'+lc2ln[row[1]]+'/'+row[0] for row in new_terms[:5]]; url_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T05:37:36.014898Z",
     "start_time": "2018-06-28T05:37:36.011405Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for new_term in new_terms:\n",
    "    print(new_term)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T13:55:39.280435Z",
     "start_time": "2018-06-29T13:55:39.274198Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    cursor.execute(\"SELECT * FROM etymologies LIMIT 30\")\n",
    "except Exception as e:\n",
    "    cursor.fetchall()\n",
    "    raise(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T03:48:48.435715Z",
     "start_time": "2018-07-02T03:48:48.431841Z"
    }
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    yield 'a'\n",
    "    return\n",
    "    yield 'b'\n",
    "    \n",
    "for a in test(): print (a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
