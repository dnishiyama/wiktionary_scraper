{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T05:11:36.761457Z",
     "start_time": "2018-07-02T05:11:36.535584Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mysql.connector, json, os, requests, re\n",
    "from bs4 import BeautifulSoup\n",
    "conn = mysql.connector.connect(\n",
    "    user=os.environ['MYSQL_DB_USER'], \n",
    "    password=os.environ['MYSQL_DB_PASSWORD'], \n",
    "    host='127.0.0.1', \n",
    "    database='etymology_explorer_staging')\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T05:11:36.844015Z",
     "start_time": "2018-07-02T05:11:36.833784Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_pos = ['adfix', 'adjective', 'adnoun', 'adverb', 'article', 'auxiliary verb', 'cardinal number', 'collective numeral',\n",
    "           'conjunction', 'coverb', 'demonstrative determiner', 'demonstrative pronoun', 'determinative', 'determiner',\n",
    "           'gerund', 'indefinite pronoun', 'infinitive', 'interjection', 'interrogative pronoun', 'intransitive verb',\n",
    "           'noun', 'number', 'numeral', 'ordinal', 'ordinal number', 'part of speech', 'participle', 'particle',\n",
    "           'personal pronoun', 'phrasal preposition', 'possessive adjective', 'possessive determiner', 'possessive pronoun',\n",
    "           'postposition', 'preposition', 'preverb', 'pronoun', 'quasi-adjective', 'reciprocal pronoun', 'reflexive pronoun',\n",
    "           'relative pronoun', 'speech disfluency', 'substantive', 'transitive', 'transitive verb', 'verb', 'verbal noun']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T05:11:36.932373Z",
     "start_time": "2018-07-02T05:11:36.929965Z"
    }
   },
   "outputs": [],
   "source": [
    "all_pos += ['suffix', 'prefix', 'infix', 'root']; all_pos; # Needed for Reconstructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Get urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Ok so I want to have the data staged somewhere so that I can check it before I update everything else. I could move it into a dataframe. I already have one that stores a ton of information. The definitions could be one big array, or it could be it's own csv with definitions as a separate list. I think I'm going to do that first. It is more flexible. And I can do that for the pronunciations. It will be the same as the other DF. I think I could also just have it append all the results to a file\n",
    "- word, language, etymology\n",
    "- word, language, pronunciation\n",
    "- word, language, pos, definition\n",
    "\n",
    "Cat is a good test for multiple etymologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T02:52:17.069423Z",
     "start_time": "2018-06-23T02:52:14.348667Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Get the list of word-language pairs\n",
    "df = pd.read_csv('~/etymology_files/ety_master.csv', \n",
    "                 usecols = ['word', 'language'], \n",
    "                 converters={'word' : str, 'language': str}\n",
    "                )\n",
    "\n",
    "# Set all non-reconstructions to be 'None'\n",
    "normal_language_rows = [not language.startswith('Proto') for language in df['language'].tolist()] #bools\n",
    "df.loc[normal_language_rows, 'language'] = None\n",
    "df = df.drop_duplicates()\n",
    "url_terms = [row[0] if row[1] is None else 'Reconstruction:'+row[1]+'/'+row[0] for row in df.values]\n",
    "urls = ['https://en.wiktionary.org/api/rest_v1/page/html/' + term for term in url_terms]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now try from MYSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "self.user = os.environ['MYSQL_DB_USER']\n",
    "self.password = os.environ['MYSQL_DB_PASSWORD']\n",
    "self.host = '127.0.0.1'\n",
    "self.database = 'etymology_explorer_staging'\n",
    "self.conn = mysql.connector.connect(user=self.user, password=self.password, host=self.host, database=self.database)\n",
    "self.cursor = self.conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T05:52:27.781044Z",
     "start_time": "2018-06-27T05:51:58.973872Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cursor.execute('SELECT word, language_name \\\n",
    "                    FROM etymologies e, languages l\\\n",
    "                    WHERE e.language_code = l.language_code AND _id NOT IN (SELECT etymology_id FROM entry_connections) \\\n",
    "                    limit 10')\n",
    "wls = [[w.decode('utf-8','replace').strip(), l.decode()] for w, l in cursor.fetchall()]; wls\n",
    "url_terms = [row[0] if not row[1].startswith('Proto') else 'Reconstruction:'+row[1]+'/'+row[0] for row in wls]; url_terms\n",
    "# for url in set(url_terms):\n",
    "#     print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('~/etymology_files/ety_master.csv',\n",
    "                 usecols = ['word', 'language'],\n",
    "                 converters={'word' : str, 'language': str})\n",
    "\n",
    "        # Set all non-reconstructions to be 'None'\n",
    "        normal_language_rows = [not language.startswith('Proto') for language in df['language'].tolist()] #bools\n",
    "        df.loc[normal_language_rows, 'language'] = None\n",
    "        df = df.drop_duplicates()\n",
    "        url_terms = [row[0] if row[1] is None else 'Reconstruction:'+row[1]+'/'+row[0] for row in df.values]\n",
    "        urls = ['https://en.wiktionary.org/api/rest_v1/page/html/' + term for term in url_terms[:5] + ['cat']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape Wiktionary Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T05:19:23.457452Z",
     "start_time": "2018-07-02T05:19:23.427030Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDefsFromPOS(ety_pronunc_pos_node):\n",
    "    keep_def_tags = ('i', 'b', 'a', 'span', None)\n",
    "    node_data = []\n",
    "    for li in list(ety_pronunc_pos_node.parent.find('ol').children): # get defs from ordered list\n",
    "        if li.name != 'li': continue # This is a newline tag\n",
    "\n",
    "        if li.find('ol'): #Ordered list means the sub items are the definition\n",
    "            for sub_li in list(li.find('ol').children):\n",
    "                if sub_li.name != 'li': continue # Skip newline tags\n",
    "\n",
    "                for child in sub_li.children:\n",
    "                    if child.name not in keep_def_tags: child.clear() #Get rid of quotes and subitems\n",
    "\n",
    "                node_data.append(sub_li.text.strip())\n",
    "\n",
    "        else: # otherwise grab the text\n",
    "\n",
    "            for child in li.children:\n",
    "                if child.name not in keep_def_tags: child.clear() #Get rid of quotes and subitems\n",
    "            node_data.append(li.text.strip())\n",
    "    return node_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T05:25:08.075141Z",
     "start_time": "2018-07-02T05:25:07.821824Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h2 id=\"English\">English</h2>\n",
      "<h3 id=\"Etymology\">Etymology</h3>\n",
      "<h3 id=\"Pronunciation\">Pronunciation</h3>\n",
      "<h3 id=\"Adjective\">Adjective</h3>\n",
      "{\n",
      "    \"term\": \"self-referential\",\n",
      "    \"English\": [\n",
      "        {\n",
      "            \"etymology\": \"self- + referential.\",\n",
      "            \"pronunciation\": \"/\\u02c8s\\u025blf \\u0279\\u025bf\\u0259\\u02c8\\u0279\\u025bn\\u0283l/\",\n",
      "            \"adjective\": [\n",
      "                \"That or who refers to itself or oneself.\",\n",
      "                \"(specifically) In a literary work: referring to the author or the author's other works.\"\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "word='self-referential'#'Reconstruction:Proto-Indo-European%2Fkerp-'; #word='Áä¨' #«µerh‚ÇÇ-\n",
    "response = requests.get(f'https://en.wiktionary.org/api/rest_v1/page/html/{word}'); response\n",
    "page = response.url.replace('https://en.wiktionary.org/api/rest_v1/page/html/', '')\n",
    "page = re.sub('Reconstruction:[^\\/]+?\\/(.*)', r'\\1', page) #Remove reconstruction text if necessary\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "page_data = {'term': page} # Variable to store the data\n",
    "\n",
    "for lang_node in soup.find_all('h2'): # Go through each Language\n",
    "    print(lang_node)\n",
    "    language = lang_node.text.strip()\n",
    "    language_entries = [{}]\n",
    "\n",
    "    for ety_pronunc_pos_node in lang_node.parent.find_all('h3'): # Go through each ety,pronu, or pos\n",
    "        print(ety_pronunc_pos_node)\n",
    "        node_data = []\n",
    "        node_class = re.sub('_\\d+| \\d+', '', ety_pronunc_pos_node.text).lower() #removed '_x' info\n",
    "#         node_text = ety_pronunc_pos_node.text.lower()\n",
    "\n",
    "        if node_class == 'etymology':\n",
    "            #Only looking at the first <p> element for etymology text\n",
    "            etymology_text = ety_pronunc_pos_node.parent.find('p').text.replace('\\u200e', '')\n",
    "            entry_data = {'etymology': etymology_text}\n",
    "            \n",
    "            for sub_ety_pos in ety_pronunc_pos_node.parent.find_all('h4'):\n",
    "                if sub_ety_pos.text.lower() in all_pos:\n",
    "                    entry_data[sub_ety_pos.text.lower()] = getDefsFromPOS(sub_ety_pos)\n",
    "\n",
    "            if any(['etymology' in entry for entry in language_entries]): #If an etymology already exists add to new entry\n",
    "                language_entries.append(entry_data)\n",
    "            else:\n",
    "                language_entries[0].update(entry_data)\n",
    "                \n",
    "        # Need to see if there are sub items of this etymology\n",
    "        elif node_class == 'pronunciation':\n",
    "            ipa_nodes = ety_pronunc_pos_node.parent.select('span.IPA') #dataquest.io/blog/web-scraping-tutorial-python/\n",
    "            if ipa_nodes: #Only add pronunciation if there are ipa_nodes\n",
    "                node_data = ipa_nodes[0].text\n",
    "                language_entries[0]['pronunciation'] = node_data\n",
    "\n",
    "        elif node_class in all_pos: # Here are the definitions\n",
    "            language_entries[0][node_class] = getDefsFromPOS(ety_pronunc_pos_node)\n",
    "\n",
    "        else: # Skip all other node_classes\n",
    "            continue\n",
    "\n",
    "        page_data[language] = language_entries #Add all the language entries to the language \n",
    "print (json.dumps(page_data, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Parsed response into SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T18:05:48.560781Z",
     "start_time": "2018-06-22T18:05:48.556838Z"
    },
    "hidden": true
   },
   "source": [
    "- Languages (1,2,3,4)\n",
    "    - Etymology (1,2,3,4)\n",
    "    - Pronunciation (1,2,3,4)\n",
    "    - POS (1,2,3,4)\n",
    "        - Definitions (1,2,3,4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Need the scraper to determine the number of entries:\n",
    "- Hand (English) has one entry with multiple POS and one etymology\n",
    "- Cat (English) has 9 entries each with one etymology and multiple POS\n",
    "- Are there any entries with multiple etymologies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T04:28:28.746580Z",
     "start_time": "2018-06-27T04:28:28.742839Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getNewKey(column, table):\n",
    "    cursor.execute(f'SELECT max({column}) FROM {table}')\n",
    "    max_entry_id = cursor.fetchone()[0]; \n",
    "    new_entry_id = max_entry_id + 1 if max_entry_id is not None else 0\n",
    "    return new_entry_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T04:41:13.589086Z",
     "start_time": "2018-06-27T04:41:13.579952Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def insert(table, **kwargs):\n",
    "    columns = [str(k) for k,v in kwargs.items()]; columns\n",
    "    values = [str(v) if type(v) != str else repr(v)  for k,v in kwargs.items()]; values\n",
    "    col_text = '('+', '.join(columns)+')'\n",
    "    val_text = '('+', '.join(values)+')'\n",
    "    sql_statement = f'INSERT INTO {table}{col_text} VALUES {val_text}'\n",
    "    print(sql_statement)\n",
    "    cursor.execute(sql_statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T06:42:59.870633Z",
     "start_time": "2018-06-27T06:42:59.868294Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T06:43:55.409629Z",
     "start_time": "2018-06-27T06:43:55.404255Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T06:43:40.375630Z",
     "start_time": "2018-06-27T06:43:40.362204Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "text = \"\"\"{'English': [{'etymology': 'From Middle English apprile, Aprill, re-Latinised from Middle English aueril, from Old French avrill, from Latin Aprƒ´lis (‚Äúof the month of the goddess Venus‚Äù), perhaps based on Etruscan êåñêåìêåêêåÄ (Apru), from Ancient Greek ŒëœÜœÅŒøŒ¥ŒØœÑŒ∑ (Aphrod√≠tƒì, ‚ÄúVenus‚Äù).', 'pronunciation': '/Ààe…™.p…π…™l/'}], 'Afrikaans': [{'noun': ['April']}], 'Cebuano': [{'etymology': 'From English April, from Middle English apprile, re-Latinized from aueril, from Old French avrill, from Latin Aprƒ´lis (‚Äúof the month of the goddess Venus‚Äù), perhaps based on Etruscan êåñêåìêåêêåÄ (Apru), from Ancient Greek ŒëœÜœÅŒøŒ¥ŒØœÑŒ∑ (Aphrod√≠tƒì, ‚ÄúVenus‚Äù).'}], 'German': [{'pronunciation': '/aÀàp Å…™l/', 'noun': ['April']}], 'Malay': [{'etymology': 'From English April, from Middle English apprile, from aueril, from Old French avrill, from Latin Aprƒ´lis.', 'pronunciation': '[aprel]'}]}\"\"\"\n",
    "table = 'entry_etymologies'\n",
    "kwargs = {'etymology': text}\n",
    "columns = [str(k) for k,v in kwargs.items()]; columns\n",
    "values = [str(v) if type(v) != str else repr(v)  for k,v in kwargs.items()]; values\n",
    "col_text = '('+', '.join(columns)+')'\n",
    "val_text = '('+', '.join(values)+')'\n",
    "\n",
    "\n",
    "cursor.execute('SET NAMES utf8mb4;')\n",
    "# cursor.execute('SET CHARACTER SET utf8mb4;')\n",
    "# cursor.execute('SET character_set_connection=utf8mb4;')\n",
    "\n",
    "cursor.execute(\"INSERT INTO entry_etymologies(etymology) VALUES (%s)\", [text.encode()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T06:48:17.401694Z",
     "start_time": "2018-06-28T06:48:17.313588Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Clear out the databases\n",
    "cursor.execute('DELETE FROM entry_connections')\n",
    "cursor.execute('DELETE FROM entry_pronunciations')\n",
    "cursor.execute('DELETE FROM entry_etymologies')\n",
    "cursor.execute('DELETE FROM entry_pos')\n",
    "cursor.execute('DELETE FROM entry_definitions')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T05:15:33.684758Z",
     "start_time": "2018-06-27T05:15:33.581663Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('/home/ubuntu/scrapy/wiktionary_scraper/output/test3.json', 'r') as results:\n",
    "    for line in results:\n",
    "        this_data = json.loads(line)\n",
    "        if this_data['term'] == 'cat': break\n",
    "        \n",
    "# print('SCRAPED DATA')\n",
    "# print(json.dumps(this_data, indent=4))\n",
    "        \n",
    "word = this_data['term']\n",
    "del this_data['term']\n",
    "\n",
    "for lang, entries in this_data.items():\n",
    "#     print()\n",
    "#     print('STORED DATA')\n",
    "    language = lang\n",
    "#     print(language)\n",
    "#     word='asdfasdf'\n",
    "    cursor.execute(f'SELECT _id FROM etymologies e, languages l WHERE word = \"{word}\" and language_name = \"{language}\" and e.language_code = l.language_code')\n",
    "    ety_id_result = cursor.fetchone(); etymology\n",
    "    if ety_id_result is not None: \n",
    "        ety_id = ety_id_result[0]\n",
    "    else:\n",
    "        ety_id = getNewKey('_id', 'etymologies') + 1\n",
    "        cursor.execute(\n",
    "                    f'INSERT INTO etymologies(_id, word, language_code) \\\n",
    "                        SELECT {ety_id}, \"{word}\", language_code FROM languages WHERE language_name = \"{language}\"')\n",
    "    \n",
    "    for entry in entries:\n",
    "        # Get a new entry key, make the entry connection\n",
    "        new_entry_id = getNewKey('entry_id', 'entry_connections'); print(\"new_entry_id:\", new_entry_id)\n",
    "        insert('entry_connections', etymology_id=ety_id, entry_id=new_entry_id)\n",
    "        \n",
    "        for node_key, node_value in entry.items():\n",
    "            if node_key == 'pronunciation':\n",
    "#                 print('node k,v:', node_key, node_value)\n",
    "                insert('entry_pronunciations', pronunciation=node_value, entry_id=new_entry_id)\n",
    "    \n",
    "            elif node_key == 'etymology':\n",
    "                insert('entry_etymologies', etymology=node_value, entry_id=new_entry_id)\n",
    "                \n",
    "            elif node_key in all_pos:\n",
    "                new_pos_key = getNewKey('pos_id', 'entry_pos'); print(\"new_pos_key:\", new_pos_key)\n",
    "                insert('entry_pos', pos=node_key, pos_id=new_pos_key, entry_id=new_entry_id)\n",
    "                \n",
    "                for definition in node_value:\n",
    "#                     print('definition:', definition, new_pos_key)\n",
    "                    insert('entry_definitions', definition=definition, pos_id=new_pos_key)\n",
    "                \n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T04:45:54.858275Z",
     "start_time": "2018-06-27T04:45:54.852448Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "These commands are mainly selecting to see if data already exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-26T21:16:54.994647Z",
     "start_time": "2018-06-26T21:16:54.946095Z"
    },
    "code_folding": [],
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('/home/ubuntu/scrapy/wiktionary_scraper/output/test3.json', 'r') as results:\n",
    "    for line in results:\n",
    "        this_data = json.loads(line)\n",
    "        if this_data['term'] == 'cat': break\n",
    "        \n",
    "print('SCRAPED DATA')\n",
    "print(json.dumps(this_data, indent=4))\n",
    "        \n",
    "word = this_data['term']\n",
    "del this_data['term']\n",
    "\n",
    "for lang, values in this_data.items():\n",
    "    print()\n",
    "    print('STORED DATA')\n",
    "    language = lang\n",
    "    \n",
    "    cursor.execute(f'SELECT _id FROM etymologies e, languages l WHERE word = \"{word}\" and language_name = \"{language}\" and e.language_code = l.language_code')\n",
    "    ety_id = cursor.fetchone()[0]; print('etymology:', ety_id)\n",
    "    \n",
    "    # Check for matching to existing entries here\n",
    "    cursor.execute(f'SELECT entry_id FROM entry_connections WHERE etymology_id = {ety_id}')\n",
    "    entry_ids = [item[0] for item in cursor.fetchall()]; print('entry_ids:', entry_ids)\n",
    "    \n",
    "    # Insert new entry ID\n",
    "#     new_entry_ids\n",
    "    # Add each element to SQL with that entry ID\n",
    "    \n",
    "    \n",
    "    #What if multiple entries\n",
    "\n",
    "    cursor.execute(f'SELECT definition FROM entry_definitions WHERE entry_id = {entry_ids[0]}')\n",
    "    definitions = cursor.fetchall(); print('definitions:', definitions)\n",
    "\n",
    "    cursor.execute(f'SELECT etymology FROM entry_etymologies WHERE entry_id= {entry_ids[0]}')\n",
    "    etymologies = cursor.fetchall(); print('etymologies:', etymologies)\n",
    "\n",
    "    cursor.execute(f'SELECT part_of_speech FROM entry_pos WHERE entry_id = {entry_ids[0]}')\n",
    "    pos = cursor.fetchall(); print('pos:', pos)\n",
    "\n",
    "    cursor.execute(f'SELECT pronunciations FROM entry_pronunciations WHERE entry_id = {entry_ids[0]}')\n",
    "    pronunciations = cursor.fetchall(); print('pronunciations:', pronunciations)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Spider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T05:11:41.596888Z",
     "start_time": "2018-07-02T05:11:40.214075Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import wiktionary_scraper.spiders.wiktionary_spider as ws\n",
    "import wiktionary_scraper.pipelines as pipelines\n",
    "import scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T04:52:57.868789Z",
     "start_time": "2018-07-02T04:52:57.866284Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ??scrapy.http.response\n",
    "# ??ws.WiktionarySpider\n",
    "# ??scrapy.Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T05:17:36.320790Z",
     "start_time": "2018-07-02T05:17:36.226273Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<200 https://en.wiktionary.org/api/rest_v1/page/html/self-referential>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term='self-referential'#'Reconstruction:Proto-Indo-European%2Fkerp-'#'Áä¨'\n",
    "url = f'https://en.wiktionary.org/api/rest_v1/page/html/{term}'; url\n",
    "temp_request = requests.get(url)\n",
    "body = temp_request.content; body\n",
    "status = temp_request.status_code; status\n",
    "spider = ws.WiktionarySpider()\n",
    "pipe = pipelines.WiktionaryScraperPipeline()\n",
    "pipe.open_spider(spider)\n",
    "request = scrapy.Request(url, meta = {'term': term})\n",
    "response = scrapy.http.response.Response(url=url, body=body, request=request, status=status); response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T05:17:38.628196Z",
     "start_time": "2018-07-02T05:17:38.594405Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'term': 'self-referential', 'status': 200, 'English': [{'etymology': 'self- +\\u200e referential.', 'pronunciation': '/Ààs…õlf …π…õf…ôÀà…π…õn Él/', 'adjective': ['That or who refers to itself or oneself.', \"(specifically) In a literary work: referring to the author or the author's other works.\"]}]}\n"
     ]
    }
   ],
   "source": [
    "for resp in spider.parse(response):\n",
    "    print(resp)\n",
    "#     print(pipe.process_item(resp, spider))\n",
    "# pipe.close_spider(spider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T05:32:34.453212Z",
     "start_time": "2018-06-28T05:32:34.322262Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cursor.execute('SELECT * FROM languages')\n",
    "lc2ln = {row[1].decode(): row[0].decode() for row in cursor.fetchall()}; lc2ln['alu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T05:37:34.419802Z",
     "start_time": "2018-06-28T05:37:24.940179Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cursor.execute('SELECT word, language_code FROM etymologies WHERE _id NOT IN (SELECT DISTINCT etymology_id FROM entry_connections)')\n",
    "new_terms = [[row[0].decode().strip(), row[1].decode()] for row in cursor.fetchall()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T05:43:32.166005Z",
     "start_time": "2018-06-28T05:43:32.161987Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url_terms = [row[0] if not row[1].endswith('-pro') else 'Reconstruction:'+lc2ln[row[1]]+'/'+row[0] for row in new_terms[:5]]; url_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T05:37:36.014898Z",
     "start_time": "2018-06-28T05:37:36.011405Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for new_term in new_terms:\n",
    "    print(new_term)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T13:55:39.280435Z",
     "start_time": "2018-06-29T13:55:39.274198Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    cursor.execute(\"SELECT * FROM etymologies LIMIT 30\")\n",
    "except Exception as e:\n",
    "    cursor.fetchall()\n",
    "    raise(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T03:48:48.435715Z",
     "start_time": "2018-07-02T03:48:48.431841Z"
    }
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    yield 'a'\n",
    "    return\n",
    "    yield 'b'\n",
    "    \n",
    "for a in test(): print (a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
