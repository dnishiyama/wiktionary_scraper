{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T15:19:56.192457Z",
     "start_time": "2018-06-30T15:19:56.058293Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mysql.connector, json, os, requests, re\n",
    "from bs4 import BeautifulSoup\n",
    "conn = mysql.connector.connect(\n",
    "    user=os.environ['MYSQL_DB_USER'], \n",
    "    password=os.environ['MYSQL_DB_PASSWORD'], \n",
    "    host='127.0.0.1', \n",
    "    database='etymology_explorer_staging')\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T15:27:38.363430Z",
     "start_time": "2018-06-30T15:27:38.359418Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_pos = ['adfix', 'adjective', 'adnoun', 'adverb', 'article', 'auxiliary verb', 'cardinal number', 'collective numeral',\n",
    "           'conjunction', 'coverb', 'demonstrative determiner', 'demonstrative pronoun', 'determinative', 'determiner',\n",
    "           'gerund', 'indefinite pronoun', 'infinitive', 'interjection', 'interrogative pronoun', 'intransitive verb',\n",
    "           'noun', 'number', 'numeral', 'ordinal', 'ordinal number', 'part of speech', 'participle', 'particle',\n",
    "           'personal pronoun', 'phrasal preposition', 'possessive adjective', 'possessive determiner', 'possessive pronoun',\n",
    "           'postposition', 'preposition', 'preverb', 'pronoun', 'quasi-adjective', 'reciprocal pronoun', 'reflexive pronoun',\n",
    "           'relative pronoun', 'speech disfluency', 'substantive', 'transitive', 'transitive verb', 'verb', 'verbal noun']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T15:27:38.801028Z",
     "start_time": "2018-06-30T15:27:38.797377Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adfix',\n",
       " 'adjective',\n",
       " 'adnoun',\n",
       " 'adverb',\n",
       " 'article',\n",
       " 'auxiliary verb',\n",
       " 'cardinal number',\n",
       " 'collective numeral',\n",
       " 'conjunction',\n",
       " 'coverb',\n",
       " 'demonstrative determiner',\n",
       " 'demonstrative pronoun',\n",
       " 'determinative',\n",
       " 'determiner',\n",
       " 'gerund',\n",
       " 'indefinite pronoun',\n",
       " 'infinitive',\n",
       " 'interjection',\n",
       " 'interrogative pronoun',\n",
       " 'intransitive verb',\n",
       " 'noun',\n",
       " 'number',\n",
       " 'numeral',\n",
       " 'ordinal',\n",
       " 'ordinal number',\n",
       " 'part of speech',\n",
       " 'participle',\n",
       " 'particle',\n",
       " 'personal pronoun',\n",
       " 'phrasal preposition',\n",
       " 'possessive adjective',\n",
       " 'possessive determiner',\n",
       " 'possessive pronoun',\n",
       " 'postposition',\n",
       " 'preposition',\n",
       " 'preverb',\n",
       " 'pronoun',\n",
       " 'quasi-adjective',\n",
       " 'reciprocal pronoun',\n",
       " 'reflexive pronoun',\n",
       " 'relative pronoun',\n",
       " 'speech disfluency',\n",
       " 'substantive',\n",
       " 'transitive',\n",
       " 'transitive verb',\n",
       " 'verb',\n",
       " 'verbal noun',\n",
       " 'suffix',\n",
       " 'prefix']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pos += ['suffix', 'prefix', 'infix', 'root']; all_pos # Needed for Reconstructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Get urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Ok so I want to have the data staged somewhere so that I can check it before I update everything else. I could move it into a dataframe. I already have one that stores a ton of information. The definitions could be one big array, or it could be it's own csv with definitions as a separate list. I think I'm going to do that first. It is more flexible. And I can do that for the pronunciations. It will be the same as the other DF. I think I could also just have it append all the results to a file\n",
    "- word, language, etymology\n",
    "- word, language, pronunciation\n",
    "- word, language, pos, definition\n",
    "\n",
    "Cat is a good test for multiple etymologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T02:52:17.069423Z",
     "start_time": "2018-06-23T02:52:14.348667Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Get the list of word-language pairs\n",
    "df = pd.read_csv('~/etymology_files/ety_master.csv', \n",
    "                 usecols = ['word', 'language'], \n",
    "                 converters={'word' : str, 'language': str}\n",
    "                )\n",
    "\n",
    "# Set all non-reconstructions to be 'None'\n",
    "normal_language_rows = [not language.startswith('Proto') for language in df['language'].tolist()] #bools\n",
    "df.loc[normal_language_rows, 'language'] = None\n",
    "df = df.drop_duplicates()\n",
    "url_terms = [row[0] if row[1] is None else 'Reconstruction:'+row[1]+'/'+row[0] for row in df.values]\n",
    "urls = ['https://en.wiktionary.org/api/rest_v1/page/html/' + term for term in url_terms]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now try from MYSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "self.user = os.environ['MYSQL_DB_USER']\n",
    "self.password = os.environ['MYSQL_DB_PASSWORD']\n",
    "self.host = '127.0.0.1'\n",
    "self.database = 'etymology_explorer_staging'\n",
    "self.conn = mysql.connector.connect(user=self.user, password=self.password, host=self.host, database=self.database)\n",
    "self.cursor = self.conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T05:52:27.781044Z",
     "start_time": "2018-06-27T05:51:58.973872Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cursor.execute('SELECT word, language_name \\\n",
    "                    FROM etymologies e, languages l\\\n",
    "                    WHERE e.language_code = l.language_code AND _id NOT IN (SELECT etymology_id FROM entry_connections) \\\n",
    "                    limit 10')\n",
    "wls = [[w.decode('utf-8','replace').strip(), l.decode()] for w, l in cursor.fetchall()]; wls\n",
    "url_terms = [row[0] if not row[1].startswith('Proto') else 'Reconstruction:'+row[1]+'/'+row[0] for row in wls]; url_terms\n",
    "# for url in set(url_terms):\n",
    "#     print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('~/etymology_files/ety_master.csv',\n",
    "                 usecols = ['word', 'language'],\n",
    "                 converters={'word' : str, 'language': str})\n",
    "\n",
    "        # Set all non-reconstructions to be 'None'\n",
    "        normal_language_rows = [not language.startswith('Proto') for language in df['language'].tolist()] #bools\n",
    "        df.loc[normal_language_rows, 'language'] = None\n",
    "        df = df.drop_duplicates()\n",
    "        url_terms = [row[0] if row[1] is None else 'Reconstruction:'+row[1]+'/'+row[0] for row in df.values]\n",
    "        urls = ['https://en.wiktionary.org/api/rest_v1/page/html/' + term for term in url_terms[:5] + ['cat']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape Wiktionary Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T15:27:47.987129Z",
     "start_time": "2018-06-30T15:27:47.970082Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDefsFromPOS(ety_pronunc_pos_node):\n",
    "    keep_def_tags = ('i', 'b', 'a', 'span', None)\n",
    "    node_data = []\n",
    "    for li in list(ety_pronunc_pos_node.parent.find('ol').children): # get defs from ordered list\n",
    "        if li.name != 'li': continue # This is a newline tag\n",
    "\n",
    "        if li.find('ol'): #Ordered list means the sub items are the definition\n",
    "            for sub_li in list(li.find('ol').children):\n",
    "                if sub_li.name != 'li': continue # Skip newline tags\n",
    "\n",
    "                for child in sub_li.children:\n",
    "                    if child.name not in keep_def_tags: child.clear() #Get rid of quotes and subitems\n",
    "\n",
    "                node_data.append(sub_li.text.strip())\n",
    "\n",
    "        else: # otherwise grab the text\n",
    "\n",
    "            for child in li.children:\n",
    "                if child.name not in keep_def_tags: child.clear() #Get rid of quotes and subitems\n",
    "            node_data.append(li.text.strip())\n",
    "    return node_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T15:27:53.531632Z",
     "start_time": "2018-06-30T15:27:53.438305Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h2 id=\"Proto-Indo-European\">Proto-Indo-European</h2>\n",
      "<h3 id=\"Suffix\">Suffix</h3>\n",
      "<h3 id=\"References\">References</h3>\n",
      "{\n",
      "    \"term\": \"Reconstruction:Proto-Indo-European%2F-r%C3%B3s\",\n",
      "    \"Proto-Indo-European\": [\n",
      "        {\n",
      "            \"suffix\": [\n",
      "                \"Forms adjectives from Caland system roots.\"\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "word='Reconstruction:Proto-Indo-European%2F-r√≥s'; #word='Áä¨' #«µerh‚ÇÇ-\n",
    "response = requests.get(f'https://en.wiktionary.org/api/rest_v1/page/html/{word}'); response\n",
    "page = response.url.replace('https://en.wiktionary.org/api/rest_v1/page/html/', '')\n",
    "page = re.sub('Reconstruction:[^\\/]+?\\/(.*)', r'\\1', page) #Remove reconstruction text if necessary\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "page_data = {'term': page} # Variable to store the data\n",
    "\n",
    "for lang_node in soup.find_all('h2'): # Go through each Language\n",
    "    print(lang_node)\n",
    "    language = lang_node.text.strip()\n",
    "    language_entries = [{}]\n",
    "\n",
    "    for ety_pronunc_pos_node in lang_node.parent.find_all('h3'): # Go through each ety,pronu, or pos\n",
    "        print(ety_pronunc_pos_node)\n",
    "        node_data = []\n",
    "        node_class = re.sub('_\\d+| \\d+', '', ety_pronunc_pos_node.text).lower() #removed '_x' info\n",
    "#         node_text = ety_pronunc_pos_node.text.lower()\n",
    "\n",
    "        if node_class == 'etymology':\n",
    "            #Only looking at the first <p> element for etymology text\n",
    "            entry_data = {'etymology': ety_pronunc_pos_node.parent.find('p').text}\n",
    "            \n",
    "            for sub_ety_pos in ety_pronunc_pos_node.parent.find_all('h4'):\n",
    "                if sub_ety_pos.text.lower() in all_pos:\n",
    "                    entry_data[sub_ety_pos.text.lower()] = getDefsFromPOS(sub_ety_pos)\n",
    "\n",
    "            if any(['etymology' in entry for entry in language_entries]): #If an etymology already exists add to new entry\n",
    "                language_entries.append(entry_data)\n",
    "            else:\n",
    "                language_entries[0].update(entry_data)\n",
    "                \n",
    "        # Need to see if there are sub items of this etymology\n",
    "        elif node_class == 'pronunciation':\n",
    "            ipa_nodes = ety_pronunc_pos_node.parent.select('span.IPA') #dataquest.io/blog/web-scraping-tutorial-python/\n",
    "            if ipa_nodes: #Only add pronunciation if there are ipa_nodes\n",
    "                node_data = ipa_nodes[0].text\n",
    "                language_entries[0]['pronunciation'] = node_data\n",
    "\n",
    "        elif node_class in all_pos: # Here are the definitions\n",
    "            language_entries[0][node_class] = getDefsFromPOS(ety_pronunc_pos_node)\n",
    "\n",
    "        else: # Skip all other node_classes\n",
    "            continue\n",
    "\n",
    "        page_data[language] = language_entries #Add all the language entries to the language \n",
    "print (json.dumps(page_data, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsed response into SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T18:05:48.560781Z",
     "start_time": "2018-06-22T18:05:48.556838Z"
    }
   },
   "source": [
    "- Languages (1,2,3,4)\n",
    "    - Etymology (1,2,3,4)\n",
    "    - Pronunciation (1,2,3,4)\n",
    "    - POS (1,2,3,4)\n",
    "        - Definitions (1,2,3,4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need the scraper to determine the number of entries:\n",
    "- Hand (English) has one entry with multiple POS and one etymology\n",
    "- Cat (English) has 9 entries each with one etymology and multiple POS\n",
    "- Are there any entries with multiple etymologies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T04:28:28.746580Z",
     "start_time": "2018-06-27T04:28:28.742839Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getNewKey(column, table):\n",
    "    cursor.execute(f'SELECT max({column}) FROM {table}')\n",
    "    max_entry_id = cursor.fetchone()[0]; \n",
    "    new_entry_id = max_entry_id + 1 if max_entry_id is not None else 0\n",
    "    return new_entry_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T04:41:13.589086Z",
     "start_time": "2018-06-27T04:41:13.579952Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insert(table, **kwargs):\n",
    "    columns = [str(k) for k,v in kwargs.items()]; columns\n",
    "    values = [str(v) if type(v) != str else repr(v)  for k,v in kwargs.items()]; values\n",
    "    col_text = '('+', '.join(columns)+')'\n",
    "    val_text = '('+', '.join(values)+')'\n",
    "    sql_statement = f'INSERT INTO {table}{col_text} VALUES {val_text}'\n",
    "    print(sql_statement)\n",
    "    cursor.execute(sql_statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T06:42:59.870633Z",
     "start_time": "2018-06-27T06:42:59.868294Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T06:43:55.409629Z",
     "start_time": "2018-06-27T06:43:55.404255Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T06:43:40.375630Z",
     "start_time": "2018-06-27T06:43:40.362204Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = \"\"\"{'English': [{'etymology': 'From Middle English apprile, Aprill, re-Latinised from Middle English aueril, from Old French avrill, from Latin Aprƒ´lis (‚Äúof the month of the goddess Venus‚Äù), perhaps based on Etruscan êåñêåìêåêêåÄ (Apru), from Ancient Greek ŒëœÜœÅŒøŒ¥ŒØœÑŒ∑ (Aphrod√≠tƒì, ‚ÄúVenus‚Äù).', 'pronunciation': '/Ààe…™.p…π…™l/'}], 'Afrikaans': [{'noun': ['April']}], 'Cebuano': [{'etymology': 'From English April, from Middle English apprile, re-Latinized from aueril, from Old French avrill, from Latin Aprƒ´lis (‚Äúof the month of the goddess Venus‚Äù), perhaps based on Etruscan êåñêåìêåêêåÄ (Apru), from Ancient Greek ŒëœÜœÅŒøŒ¥ŒØœÑŒ∑ (Aphrod√≠tƒì, ‚ÄúVenus‚Äù).'}], 'German': [{'pronunciation': '/aÀàp Å…™l/', 'noun': ['April']}], 'Malay': [{'etymology': 'From English April, from Middle English apprile, from aueril, from Old French avrill, from Latin Aprƒ´lis.', 'pronunciation': '[aprel]'}]}\"\"\"\n",
    "table = 'entry_etymologies'\n",
    "kwargs = {'etymology': text}\n",
    "columns = [str(k) for k,v in kwargs.items()]; columns\n",
    "values = [str(v) if type(v) != str else repr(v)  for k,v in kwargs.items()]; values\n",
    "col_text = '('+', '.join(columns)+')'\n",
    "val_text = '('+', '.join(values)+')'\n",
    "\n",
    "\n",
    "cursor.execute('SET NAMES utf8mb4;')\n",
    "# cursor.execute('SET CHARACTER SET utf8mb4;')\n",
    "# cursor.execute('SET character_set_connection=utf8mb4;')\n",
    "\n",
    "cursor.execute(\"INSERT INTO entry_etymologies(etymology) VALUES (%s)\", [text.encode()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T06:48:17.401694Z",
     "start_time": "2018-06-28T06:48:17.313588Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clear out the databases\n",
    "cursor.execute('DELETE FROM entry_connections')\n",
    "cursor.execute('DELETE FROM entry_pronunciations')\n",
    "cursor.execute('DELETE FROM entry_etymologies')\n",
    "cursor.execute('DELETE FROM entry_pos')\n",
    "cursor.execute('DELETE FROM entry_definitions')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T05:15:33.684758Z",
     "start_time": "2018-06-27T05:15:33.581663Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/home/ubuntu/scrapy/wiktionary_scraper/output/test3.json', 'r') as results:\n",
    "    for line in results:\n",
    "        this_data = json.loads(line)\n",
    "        if this_data['term'] == 'cat': break\n",
    "        \n",
    "# print('SCRAPED DATA')\n",
    "# print(json.dumps(this_data, indent=4))\n",
    "        \n",
    "word = this_data['term']\n",
    "del this_data['term']\n",
    "\n",
    "for lang, entries in this_data.items():\n",
    "#     print()\n",
    "#     print('STORED DATA')\n",
    "    language = lang\n",
    "#     print(language)\n",
    "#     word='asdfasdf'\n",
    "    cursor.execute(f'SELECT _id FROM etymologies e, languages l WHERE word = \"{word}\" and language_name = \"{language}\" and e.language_code = l.language_code')\n",
    "    ety_id_result = cursor.fetchone(); etymology\n",
    "    if ety_id_result is not None: \n",
    "        ety_id = ety_id_result[0]\n",
    "    else:\n",
    "        ety_id = getNewKey('_id', 'etymologies') + 1\n",
    "        cursor.execute(\n",
    "                    f'INSERT INTO etymologies(_id, word, language_code) \\\n",
    "                        SELECT {ety_id}, \"{word}\", language_code FROM languages WHERE language_name = \"{language}\"')\n",
    "    \n",
    "    for entry in entries:\n",
    "        # Get a new entry key, make the entry connection\n",
    "        new_entry_id = getNewKey('entry_id', 'entry_connections'); print(\"new_entry_id:\", new_entry_id)\n",
    "        insert('entry_connections', etymology_id=ety_id, entry_id=new_entry_id)\n",
    "        \n",
    "        for node_key, node_value in entry.items():\n",
    "            if node_key == 'pronunciation':\n",
    "#                 print('node k,v:', node_key, node_value)\n",
    "                insert('entry_pronunciations', pronunciation=node_value, entry_id=new_entry_id)\n",
    "    \n",
    "            elif node_key == 'etymology':\n",
    "                insert('entry_etymologies', etymology=node_value, entry_id=new_entry_id)\n",
    "                \n",
    "            elif node_key in all_pos:\n",
    "                new_pos_key = getNewKey('pos_id', 'entry_pos'); print(\"new_pos_key:\", new_pos_key)\n",
    "                insert('entry_pos', pos=node_key, pos_id=new_pos_key, entry_id=new_entry_id)\n",
    "                \n",
    "                for definition in node_value:\n",
    "#                     print('definition:', definition, new_pos_key)\n",
    "                    insert('entry_definitions', definition=definition, pos_id=new_pos_key)\n",
    "                \n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T04:45:54.858275Z",
     "start_time": "2018-06-27T04:45:54.852448Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These commands are mainly selecting to see if data already exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-26T21:16:54.994647Z",
     "start_time": "2018-06-26T21:16:54.946095Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/home/ubuntu/scrapy/wiktionary_scraper/output/test3.json', 'r') as results:\n",
    "    for line in results:\n",
    "        this_data = json.loads(line)\n",
    "        if this_data['term'] == 'cat': break\n",
    "        \n",
    "print('SCRAPED DATA')\n",
    "print(json.dumps(this_data, indent=4))\n",
    "        \n",
    "word = this_data['term']\n",
    "del this_data['term']\n",
    "\n",
    "for lang, values in this_data.items():\n",
    "    print()\n",
    "    print('STORED DATA')\n",
    "    language = lang\n",
    "    \n",
    "    cursor.execute(f'SELECT _id FROM etymologies e, languages l WHERE word = \"{word}\" and language_name = \"{language}\" and e.language_code = l.language_code')\n",
    "    ety_id = cursor.fetchone()[0]; print('etymology:', ety_id)\n",
    "    \n",
    "    # Check for matching to existing entries here\n",
    "    cursor.execute(f'SELECT entry_id FROM entry_connections WHERE etymology_id = {ety_id}')\n",
    "    entry_ids = [item[0] for item in cursor.fetchall()]; print('entry_ids:', entry_ids)\n",
    "    \n",
    "    # Insert new entry ID\n",
    "#     new_entry_ids\n",
    "    # Add each element to SQL with that entry ID\n",
    "    \n",
    "    \n",
    "    #What if multiple entries\n",
    "\n",
    "    cursor.execute(f'SELECT definition FROM entry_definitions WHERE entry_id = {entry_ids[0]}')\n",
    "    definitions = cursor.fetchall(); print('definitions:', definitions)\n",
    "\n",
    "    cursor.execute(f'SELECT etymology FROM entry_etymologies WHERE entry_id= {entry_ids[0]}')\n",
    "    etymologies = cursor.fetchall(); print('etymologies:', etymologies)\n",
    "\n",
    "    cursor.execute(f'SELECT part_of_speech FROM entry_pos WHERE entry_id = {entry_ids[0]}')\n",
    "    pos = cursor.fetchall(); print('pos:', pos)\n",
    "\n",
    "    cursor.execute(f'SELECT pronunciations FROM entry_pronunciations WHERE entry_id = {entry_ids[0]}')\n",
    "    pronunciations = cursor.fetchall(); print('pronunciations:', pronunciations)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Spider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T14:20:41.440479Z",
     "start_time": "2018-06-30T14:20:41.437392Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import wiktionary_scraper.spiders.wiktionary_spider as ws\n",
    "import scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T14:44:35.956804Z",
     "start_time": "2018-06-30T14:44:35.909724Z"
    }
   },
   "outputs": [],
   "source": [
    "??scrapy.http.response\n",
    "??ws.WiktionarySpider\n",
    "??scrapy.Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T14:47:14.831962Z",
     "start_time": "2018-06-30T14:47:14.671852Z"
    }
   },
   "outputs": [],
   "source": [
    "term='-r√≥s'#'Áä¨'\n",
    "url = f'https://en.wiktionary.org/api/rest_v1/page/html/{term}'; url\n",
    "body = requests.get(url).content\n",
    "spider = ws.WiktionarySpider()\n",
    "request = scrapy.Request(url, meta = {'term': term})\n",
    "response = scrapy.http.response.Response(url=url, body=body, request=request); response\n",
    "# page = response.url.replace('https://en.wiktionary.org/api/rest_v1/page/html/', '')\n",
    "# page = re.sub('Reconstruction:[^\\/]+?\\/(.*)', r'\\1', page) #Remove reconstruction text if necessary\n",
    "# print(page)\n",
    "# soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T14:47:15.094967Z",
     "start_time": "2018-06-30T14:47:15.089186Z"
    }
   },
   "outputs": [],
   "source": [
    "for a in spider.parse(response):\n",
    "    print (a)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T14:30:23.669286Z",
     "start_time": "2018-06-30T14:30:23.666168Z"
    }
   },
   "outputs": [],
   "source": [
    "response.body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T05:32:34.453212Z",
     "start_time": "2018-06-28T05:32:34.322262Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cursor.execute('SELECT * FROM languages')\n",
    "lc2ln = {row[1].decode(): row[0].decode() for row in cursor.fetchall()}; lc2ln['alu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T05:37:34.419802Z",
     "start_time": "2018-06-28T05:37:24.940179Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cursor.execute('SELECT word, language_code FROM etymologies WHERE _id NOT IN (SELECT DISTINCT etymology_id FROM entry_connections)')\n",
    "new_terms = [[row[0].decode().strip(), row[1].decode()] for row in cursor.fetchall()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T05:43:32.166005Z",
     "start_time": "2018-06-28T05:43:32.161987Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url_terms = [row[0] if not row[1].endswith('-pro') else 'Reconstruction:'+lc2ln[row[1]]+'/'+row[0] for row in new_terms[:5]]; url_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T05:37:36.014898Z",
     "start_time": "2018-06-28T05:37:36.011405Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for new_term in new_terms:\n",
    "    print(new_term)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T13:55:39.280435Z",
     "start_time": "2018-06-29T13:55:39.274198Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    cursor.execute(\"SELECT * FROM etymologies LIMIT 30\")\n",
    "except Exception as e:\n",
    "    cursor.fetchall()\n",
    "    raise(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
